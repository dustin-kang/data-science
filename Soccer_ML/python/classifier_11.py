#!/usr/bin/env python
# coding: utf-8

# # Model Baseline 
# <aside>
# 
# ### **ğŸ’¡ 4) ë¨¸ì‹ ëŸ¬ë‹ ë°©ì‹ ì ìš© ë° êµì°¨ê²€ì¦**
# 
# ë°ì´í„°ì˜ íƒìƒ‰ê³¼ ì „ì²˜ë¦¬ ì‘ì—…ì´ ëë‚¬ë‹¤ë©´ **ëª¨ë¸ë§ì„ í†µí•´ ë² ì´ìŠ¤ë¼ì¸ê³¼ì˜ ì„±ëŠ¥ ë¹„êµ**ë¥¼ í•´ë´…ë‹ˆë‹¤.
# 
# - Linear / Tree-based / Ensemble ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”. (ë‹¤ì–‘í•˜ê²Œ ì‹œë„í•´ë³´ì‹œëŠ” ê±¸ ì¶”ì²œí•©ë‹ˆë‹¤.)
# - í‰ê°€ì§€í‘œë¥¼ ê³„ì‚° í›„ ë² ì´ìŠ¤ë¼ì¸ê³¼ ë¹„êµí•´ë³´ì„¸ìš”.
# - ì–´ëŠì •ë„ ì„±ëŠ¥ì´ ë‚˜ì™”ë‹¤ë©´, êµì°¨ ê²€ì¦ (ì´í•˜ CV)ì„ í†µí•´ì„œ ì¼ë°˜í™”ë  ê°€ëŠ¥ì„±ì´ ìˆëŠ”ì§€ í™•ì¸í•´ë´…ë‹ˆë‹¤.
# - ëª¨ë¸ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ë°©ë²•ì„ ì ìš©í•´ë³´ì„¸ìš”.
#     - Hyperparameter tuning, etc.
# - ìµœì†Œ 2ê°œ ì´ìƒì˜ ëª¨ë¸ì„ ë§Œë“¤ì–´ì„œ validation ì ìˆ˜ë¥¼ ë³´ê³ í•˜ì„¸ìš”.
# - ìµœì¢… ëª¨ë¸ì˜ test ì ìˆ˜ë¥¼ ë³´ê³ í•˜ì„¸ìš”.
# 
# ### **íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•œ í›„, ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€ë‹µí•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.**
# 
# 1. ëª¨ë¸ì„ í•™ìŠµí•œ í›„ì— ë² ì´ìŠ¤ë¼ì¸ë³´ë‹¤ ì˜ ë‚˜ì™”ë‚˜ìš”? ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?
# 2. ëª¨ë¸ ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•´ ì–´ë–¤ ë°©ë²•ì„ ì ìš©í–ˆë‚˜ìš”? ê·¸ ë°©ë²•ì„ ì„ íƒí•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?
# 3. ìµœì¢… ëª¨ë¸ì— ê´€í•´ ì„¤ëª…í•˜ì„¸ìš”.
# </aside>

# # Spliting Dataset
# - target ê°’ì„ `position` ìœ¼ë¡œ í•˜ê³  ì„ ìˆ˜ë“¤ì˜ ëŠ¥ë ¥ì„ í†µí•´ í¬ì§€ì…˜ê°’ì„ ë¶„ë¥˜í•  ì˜ˆì •.

# In[1]:


import pandas as pd
import numpy as np
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.pyplot as plt

# ì „ì²´ ì»¬ëŸ¼ ì¶œë ¥í•˜ê¸°
pd.set_option('display.max_columns', None)

warnings.filterwarnings("ignore")

df_4 = pd.read_csv('../data/cls_data_4p.csv')
df_11 = pd.read_csv('../data/cls_data_11p.csv')


# In[2]:


from sklearn.model_selection import train_test_split 

# íƒ€ê²Ÿ(target)
target = 'position'


# í›ˆë ¨ ë°ì´í„° ì…‹ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì…‹ ë¶„ë¦¬
train, test = train_test_split(df_11, random_state=2, train_size=.75, stratify=df_11[target])
# í›ˆë¸ ë°ì´í„°ì…‹ì—ì„œ í›ˆë ¨ë°ì´í„° ì…‹ê³¼ ê²€ì¦ ë°ì´í„° ì…‹ ë¶„ë¦¬
train, val = train_test_split(train, random_state=2, train_size=.75, stratify=train[target])

# íŠ¹ì„±(features)
features = train.columns.drop(target)


# In[3]:


train.shape, val.shape, test.shape


# In[4]:


# X (features)
X_train = train[features] 
X_val = val[features]
X_test = test[features]

# y (Target)
y_train = train[target]
y_val = val[target] 
y_test = test[target]


# ## Classifier Modeling

# In[1]:


get_ipython().system('pip install --upgrade category_encoders')


# In[2]:


get_ipython().system('pip install --upgrade xgboost')


# In[3]:


# íŒŒì´í”„ë¼ì¸ #
from sklearn.pipeline import make_pipeline, Pipeline

# ì¸ì½”ë” #
from category_encoders import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler

# ëª¨ë¸ë§ #
from sklearn.linear_model import LogisticRegressionCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

# í‰ê°€ #
from sklearn.metrics import classification_report, plot_confusion_matrix


# ### make pipeline
# - `str` ë°ì´í„° ìë£Œí˜•ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ì»¬ëŸ¼ì„ 0ê³¼ 1ë¡œ ë°”ê¾¸ëŠ” **OneHotEncoder(ì›í•« ì¸ì½”ë”)**ë¥¼ ì‚¬ìš©í•¨.
# - ì´í›„ í›ˆë ¨ ë°ì´í„°ì…‹ì€ `fit_transform`ì„ ì§„í–‰í•¨.
# - ê²€ì¦, ì‹œí—˜ ë°ì´í„°ì…‹ì€ `transform`ì„ ì§„í–‰í•¨.
# 

# In[6]:


pipe = make_pipeline(
    OneHotEncoder(cols=['preferred_foot','body_type','work_rate_Attaking','work_rate_defensive'], use_cat_names=True),
    # SimpleImputer(missing_values=np.nan, strategy='mean'),
    MinMaxScaler()
)

X_train_transform = pipe.fit_transform(X_train)
X_val_transform = pipe.transform(X_val)
X_test_transform = pipe.transform(X_test)


# ### LogisticRegression (ë¡œì§€ìŠ¤í‹± íšŒê·€)

# In[7]:


clf = LogisticRegressionCV(max_iter=100)
clf = clf.fit(X_train_transform, y_train)
y_pred = clf.predict(X_val_transform)


# In[8]:


print(classification_report(y_val, y_pred))


# In[10]:


label = ['Attack_C', 'Defence_C', 'Midfielder_C', 'Def_Midfielder', 'GK',
         'Attack_L', 'Defence_L', 'Midfielder_L', 'Attack_R', 'Defence_R', 'Midfielder_R']
fig, ax = plt.subplots(figsize=(15, 15))
plot_confusion_matrix(clf, 
                              X_val_transform, y_val,
                              display_labels = label,
                              cmap = 'Blues',
                              normalize='true',
                              ax = ax)
plt.title('Logistic Regression(Position)', fontsize=15);


# ### Decision Tree (ê²°ì •íŠ¸ë¦¬)

# In[11]:


clf = DecisionTreeClassifier()
clf.fit(X_train_transform, y_train)
y_pred = clf.predict(X_val_transform)
print(classification_report(y_val, y_pred))


# In[12]:


label = ['Attack_C', 'Defence_C', 'Midfielder_C', 'Def_Midfielder', 'GK',
         'Attack_L', 'Defence_L', 'Midfielder_L', 'Attack_R', 'Defence_R', 'Midfielder_R']
fig, ax = plt.subplots(figsize=(15, 15))
plot_confusion_matrix(clf, 
                              X_val_transform, y_val,
                              display_labels = label,
                              cmap = 'Blues',
                              normalize='true',
                              ax = ax)
plt.title('DecisionTree Classification', fontsize=15);


# ### RandomForest (ëœë¤ í¬ë ˆìŠ¤íŠ¸)

# In[13]:


clf = RandomForestClassifier()
clf.fit(X_train_transform, y_train)
y_pred = clf.predict(X_val_transform)
print(classification_report(y_val, y_pred))


# In[14]:


label = ['Attack_C', 'Defence_C', 'Midfielder_C', 'Def_Midfielder', 'GK',
         'Attack_L', 'Defence_L', 'Midfielder_L', 'Attack_R', 'Defence_R', 'Midfielder_R']
fig, ax = plt.subplots(figsize=(15, 15))
plot_confusion_matrix(clf, 
                              X_val_transform, y_val,
                              display_labels = label,
                              cmap = 'Blues',
                              normalize='true',
                              ax = ax)
plt.title('RandomForest Classifier(Position)', fontsize=15);


# ### XGBoost

# In[ ]:


clf = XGBClassifier()
clf.fit(X_train_transform, y_train)
y_pred = clf.predict(X_val_transform)
print(classification_report(y_val, y_pred))


# In[ ]:


label = ['Attack_C', 'Defence_C', 'Midfielder_C', 'Def_Midfielder', 'GK',
         'Attack_L', 'Defence_L', 'Midfielder_L', 'Attack_R', 'Defence_R', 'Midfielder_R']
fig, ax = plt.subplots(figsize=(15, 15))
plot_confusion_matrix(clf, 
                              X_val_transform, y_val,
                              display_labels = label,
                              cmap = 'Blues',
                              normalize='true',
                              ax = ax)
plt.title('XGBoost Classifier(Position)', fontsize=15);


# ## ê²°ë¡ ì ìœ¼ë¡œ
# ê°€ì¥ ì •í™•ë„ê°€ ë†’ì•˜ë˜ ëª¨ë¸ì€ LogisticRegressionì´ì§€ë§Œ ê·¸ì™¸ë¡œë„ XGBoostë‚˜ ëœë¤í¬ë ˆìŠ¤íŠ¸ë„ ë¯¸ì„¸í•œì°¨ì´ë¼ ë¹„ìŠ·í•œ ì •í™•ë„ë¥¼ ë‚˜íƒ€ë‚´ê³  ìˆìŠµë‹ˆë‹¤.
